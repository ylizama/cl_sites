{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/borrador_conjunto.txt', 'r') \n",
    "text = file.read() \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_spanish = ['un', 'una', 'unas', 'unos', 'uno', 'sobre', 'todo', 'también', 'tras', 'otro', 'algún', 'alguno', 'alguna', 'algunos', 'algunas', 'ser', 'es', 'soy', 'eres', 'somos', 'sois', 'estoy', 'esta', 'estamos', 'estais', 'estan', 'como', 'en', 'para', 'atras', 'porque', 'por qué',  'estaba', 'ante', 'antes', 'siendo', 'ambos', 'pero', 'por', 'poder', 'puede', 'puedo', 'podemos', 'podeis', 'pueden', 'fui', 'fue', 'fuimos', 'fueron', 'hacer', 'hago', 'hace', 'hacemos', 'haceis', 'hacen', 'cada', 'fin', 'incluso', 'primero', 'desde', 'conseguir', 'consigo', 'consigue', 'consigues', 'conseguimos', 'consiguen', 'ir', 'voy', 'va', 'vamos', 'vais', 'van', 'vaya', 'gueno', 'ha', 'el', 'la', 'lo', 'las', 'los', 'su', 'aqui', 'mio', 'tuyo', 'ellos', 'ellas', 'nos', 'nosotros', 'vosotros', 'vosotras', 'si', 'dentro', 'solo', 'solamente', 'saber', 'sabes', 'sabe', 'sabemos', 'sabeis', 'saben', 'ultimo', 'largo', 'bastante', 'haces', 'muchos', 'aquellos', 'aquellas', 'sus', 'entonces', 'tiempo', 'verdad', 'verdadero', 'verdadera', 'cierto', 'ciertos', 'cierta', 'ciertas', 'intentar', 'intento', 'intenta', 'intentas', 'intentamos', 'intentais', 'intentan', 'dos', 'bajo', 'arriba', 'encima', 'usar', 'uso', 'usas', 'usa', 'usamos', 'usais', 'usan', 'emplear', 'empleo', 'empleas', 'emplean', 'ampleamos', 'empleais', 'valor', 'muy', 'era', 'eras', 'eramos', 'eran', 'modo', 'bien', 'cual', 'cuando', 'donde', 'mientras', 'quien', 'con', 'entre', 'sin', 'trabajo', 'trabajar', 'trabajas', 'trabaja', 'trabajamos', 'trabajais', 'trabajan', 'podria', 'podrias', 'podriamos', 'podrian', 'podriais', 'yo', 'aquel', 'a', 'en', 'de', 'para', 'por', 'según', 'sin', 'sobre', 'tras', 'bajo', 'contra', 'hacia', 'hasta', 'rt', 'que', 'se', 'no', 'del', 'al', 'http', 'https', 'y', 'más', 'todos', 'año', 'será', 'este', 'vía', 'les', 'ni', 'dice', 'le', 'está', 'qué', 'hay', 'htt', 'quiere', 'nuestra', 'sí', 'of', 'in', 'años', 'firma' , 'firman', 'nuevo', 'hoy', 'ayer', 'inicio', 'ya', 'día','son', 'final', 'and', 'with', 'you', 'mundo', 'gran', 'sol', 'recibe', 'millones',  'gracias', 'hermana','me', 'eso',  'we', 'after',  'dijo','lleve', 'nuevamente', 'ahora', 'ese',  'han', 'sino', 'tal', 'mismos', 'estos', 'así', 'ver', 'esto', 'esta', 'sido', 'manera', 'sigo', 'da', 'esa', 'aunque', 'están', 'mil', 'además', 'había', 'él', 'después', 'pues', 'vez', 'quienes', 'página', 'conjunto 15122015', '63 borrador']\n",
    "\n",
    "abc = string.ascii_lowercase \n",
    "punct_signs = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import operator\n",
    "from itertools import islice\n",
    "import string \n",
    "from tabulate import tabulate\n",
    "\n",
    "def stopWordsInGrams(grams):    \n",
    "    count = 0\n",
    "    for w in grams:\n",
    "        if w in stop_words_spanish:\n",
    "            count = count + 1                \n",
    "    return count/len(grams)  \n",
    "\n",
    "def isNumber(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def getNGram(text, n, stop_words, m):\n",
    "    text = text.lower()\n",
    "    ngramas = ngrams(text.split(), n)\n",
    "    h_dict = {}   \n",
    "    for grams in ngramas:\n",
    "        if stopWordsInGrams(grams) > 0.34:\n",
    "            continue\n",
    "        words = ' '.join(grams)        \n",
    "        words = words.lower() \n",
    "        words = ''.join(e for e in words if e.isalnum() or e == ' ')    \n",
    "        words = words.strip()  \n",
    "        if  words in stop_words or words in punct_signs or words == '' or words in abc or isNumber(words) or len(words.split(' ')) != n:\n",
    "             continue\n",
    "        if words in h_dict:\n",
    "            h_dict[words] = h_dict[words] + 1\n",
    "        else: \n",
    "            h_dict[words] = 1 \n",
    "    sorted_dict = sorted(h_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    if m is -1:\n",
    "        return list(sorted_dict)\n",
    "    else:\n",
    "        return list(islice(sorted_dict, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 Unigramas más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram              Number\n",
      "---------------  --------\n",
      "conflicto             178\n",
      "víctimas              168\n",
      "derechos              162\n",
      "paz                   134\n",
      "justicia              120\n",
      "comisión              108\n",
      "reparación            106\n",
      "reconocimiento        100\n",
      "repetición             98\n",
      "humanos                93\n",
      "medidas                92\n",
      "acuerdo                89\n",
      "responsabilidad        84\n",
      "especial               82\n",
      "personas               79\n",
      "sala                   72\n",
      "conjunto               68\n",
      "caso                   67\n",
      "nacional               67\n",
      "borrador               63\n",
      "---------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final = getNGram(text, 1, stop_words_spanish, 20)\n",
    "print(tabulate(final, ['Ngram', 'Number']))\n",
    "print('---------------------------------')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 Bigramas más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram                        Number\n",
      "-------------------------  --------\n",
      "derechos humanos                 92\n",
      "borrador conjunto                63\n",
      "jurisdicción especial            44\n",
      "gobierno nacional                38\n",
      "derecho internacional            33\n",
      "sistema integral                 32\n",
      "conflicto armado                 32\n",
      "acuerdo final                    28\n",
      "reparación colectiva             21\n",
      "verdad justicia                  21\n",
      "personas dadas                   20\n",
      "justicia reparación              20\n",
      "internacional humanitario        19\n",
      "amnistía o                       15\n",
      "graves violaciones               14\n",
      "directa o                        14\n",
      "enfoque territorial              12\n",
      "reparación integral              12\n",
      "o indulto                        12\n",
      "graves infracciones              12\n",
      "---------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final2 = getNGram(text, 2, stop_words_spanish, 20)\n",
    "print(tabulate(final2, ['Ngram', 'Number']))\n",
    "print('---------------------------------')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigramas que contienen la palabra 'Conflicto' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram                    Number\n",
      "---------------------  --------\n",
      "conflicto armado             32\n",
      "conflicto o                   4\n",
      "conflicto incluyendo          2\n",
      "conflicto requiere            2\n",
      "conflicto teniendo            2\n",
      "conflicto constituye          2\n",
      "conflicto puedan              2\n",
      "conflicto afectó              2\n",
      "conflicto sistema             1\n",
      "conflicto e                   1\n",
      "conflicto deben               1\n",
      "conflicto debe                1\n",
      "conflicto reconozcan          1\n",
      "conflicto asegurar            1\n",
      "conflicto mediante            1\n",
      "conflicto 5136                1\n",
      "conflicto hubieran            1\n",
      "conflicto 51113               1\n",
      "conflictos deberá             1\n",
      "conflicto colombia            1\n",
      "conflicto permitirá           1\n",
      "conflicto enviará             1\n",
      "conflicto mismo               1\n",
      "conflicto debería             1\n",
      "conflicto tales               1\n",
      "conflicto responden           1\n",
      "conflicto reprodujo           1\n",
      "conflicto restablecer         1\n",
      "conflicto podrán              1\n",
      "conflicto promover            1\n",
      "conflicto pondrá              1\n",
      "conflicto 5134                1\n",
      "conflicto promoción           1\n",
      "conflicto 4                   1\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "final3 = getNGram(text, 2, stop_words_spanish, -1)\n",
    "final4 = []\n",
    "for i in final3:\n",
    "    if 'conflicto' in i[0]:\n",
    "        final4.append(i)\n",
    "    \n",
    "print(tabulate(final4, ['Ngram', 'Number']))\n",
    "print('---------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigramas que contienen la palabra 'Víctimas' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram                      Number\n",
      "-----------------------  --------\n",
      "5 víctimas                      4\n",
      "víctimas incluyendo             3\n",
      "víctimas mujeres                2\n",
      "víctimas existentes             2\n",
      "víctimas directas               2\n",
      "víctimas gozan                  1\n",
      "víctimas deben                  1\n",
      "víctimas terminar               1\n",
      "víctimas iniciamos              1\n",
      "víctimas debería                1\n",
      "sesenta víctimas                1\n",
      "víctimas en                     1\n",
      "colombianas víctimas            1\n",
      "víctimas pertenecientes         1\n",
      "víctimas testigos               1\n",
      "víctimas tienen                 1\n",
      "víctimas adecuarla              1\n",
      "agenda víctimas                 1\n",
      "sea víctima                     1\n",
      "víctimas 514                    1\n",
      "víctimas causadas               1\n",
      "víctimas mediante               1\n",
      "otras víctimas                  1\n",
      "víctimas invitadas              1\n",
      "víctimas 18                     1\n",
      "punto víctimas                  1\n",
      "víctimas 51114                  1\n",
      "víctimas viajaron               1\n",
      "víctimas o                      1\n",
      "víctimas contribuir             1\n",
      "víctima 51                      1\n",
      "víctimas contará                1\n",
      "víctimas marcar                 1\n",
      "víctimas organizaciones         1\n",
      "víctimas deberá                 1\n",
      "3000 víctimas                   1\n",
      "víctimas conforme               1\n",
      "víctimas buscará                1\n",
      "víctimas participaron           1\n",
      "víctimas residentes             1\n",
      "víctimas tanto                  1\n",
      "víctimas objeto                 1\n",
      "pública víctimas                1\n",
      "víctima o                       1\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "final3 = getNGram(text, 2, stop_words_spanish, -1)\n",
    "final4 = []\n",
    "for i in final3:\n",
    "    if 'víctima' in i[0]:\n",
    "        final4.append(i)\n",
    "    \n",
    "print(tabulate(final4, ['Ngram', 'Number']))\n",
    "print('---------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Top 20 Unigramas en la misma oración que 'conflicto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram         Number\n",
      "----------  --------\n",
      "víctimas          60\n",
      "reparación        42\n",
      "derechos          40\n",
      "repetición        32\n",
      "personas          31\n",
      "comisión          26\n",
      "marco             26\n",
      "acuerdo           25\n",
      "gobierno          25\n",
      "armado            24\n",
      "nacional          23\n",
      "contribuir        21\n",
      "justicia          19\n",
      "medidas           19\n",
      "integral          19\n",
      "paz               18\n",
      "directa           18\n",
      "humanos           18\n",
      "desarrollo        17\n",
      "especial          17\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sentences = text.split('.')\n",
    "regexp = re.compile(r'[ .,;\\'\\\"]conflicto[ .,;\\'\\\"]')\n",
    "data_paz = ''\n",
    "for s in sentences: \n",
    "    if regexp.search(s.lower()): \n",
    "        data_paz = data_paz + '\\n' + s\n",
    "\n",
    "stop_words = stop_words_spanish\n",
    "stop_words.append('conflicto')\n",
    "final5 = getNGram(data_paz, 1,stop_words , 20)\n",
    "print(tabulate(final5, ['Ngram', 'Number']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 Bigramas en la misma oración que 'conflicto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram                        Number\n",
      "-------------------------  --------\n",
      "gobierno nacional                18\n",
      "derechos humanos                 18\n",
      "personas dadas                   14\n",
      "directa o                        14\n",
      "sistema integral                 11\n",
      "o indirecta                      11\n",
      "reparación colectiva             10\n",
      "jurisdicción especial             9\n",
      "enfoque territorial               7\n",
      "internacional humanitario         6\n",
      "hemos acordado                    6\n",
      "verdad justicia                   6\n",
      "justicia reparación               6\n",
      "derecho internacional             6\n",
      "graves violaciones                6\n",
      "e infracciones                    6\n",
      "múltiples causas                  5\n",
      "reparación integral               5\n",
      "acuerdo general                   5\n",
      "comisión histórica                5\n"
     ]
    }
   ],
   "source": [
    "sentences = text.split('.')\n",
    "regexp = re.compile(r'[ .,;\\'\\\"]conflicto[ .,;\\'\\\"]')\n",
    "data_paz = ''\n",
    "for s in sentences: \n",
    "    if regexp.search(s.lower()): \n",
    "        data_paz = data_paz + '\\n' + s\n",
    "\n",
    "stop_words = stop_words_spanish\n",
    "stop_words.append('conflicto')\n",
    "final6 = getNGram(data_paz, 2,stop_words , 20)\n",
    "print(tabulate(final6, ['Ngram', 'Number']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 Unigramas en la misma oración que 'víctimas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram             Number\n",
      "--------------  --------\n",
      "derechos              58\n",
      "reparación            50\n",
      "repetición            33\n",
      "justicia              30\n",
      "reconocimiento        27\n",
      "nacional              26\n",
      "integral              25\n",
      "organizaciones        24\n",
      "participación         24\n",
      "humanos               23\n",
      "acuerdo               22\n",
      "gobierno              21\n",
      "paz                   20\n",
      "comisión              20\n",
      "medidas               19\n",
      "satisfacción          18\n",
      "parte                 17\n",
      "marco                 17\n",
      "contribuir            15\n",
      "incluyendo            15\n"
     ]
    }
   ],
   "source": [
    "sentences = text.split('.')\n",
    "regexp = re.compile(r'[ .,;\\'\\\"]víctimas[ .,;\\'\\\"]')\n",
    "data_paz = ''\n",
    "for s in sentences: \n",
    "    if regexp.search(s.lower()): \n",
    "        data_paz = data_paz + '\\n' + s\n",
    "\n",
    "stop_words = stop_words_spanish\n",
    "stop_words.append('víctimas')\n",
    "final6 = getNGram(data_paz, 1,stop_words , 20)\n",
    "print(tabulate(final6, ['Ngram', 'Number']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 Bigramas en la misma oración que 'víctimas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram                        Number\n",
      "-------------------------  --------\n",
      "derechos humanos                 23\n",
      "gobierno nacional                17\n",
      "sistema integral                 12\n",
      "reparación integral              10\n",
      "verdad justicia                   9\n",
      "justicia reparación               9\n",
      "graves violaciones                6\n",
      "hemos acordado                    5\n",
      "enfoque territorial               5\n",
      "jurisdicción especial             5\n",
      "reparación colectiva              5\n",
      "internacional humanitario         4\n",
      "acuerdo final                     4\n",
      "personas desaparecidas            4\n",
      "derecho internacional             4\n",
      "estas instancias                  3\n",
      "e infracciones                    3\n",
      "múltiples causas                  3\n",
      "farcep hemos                      3\n",
      "acuerdo general                   3\n"
     ]
    }
   ],
   "source": [
    "sentences = text.split('.')\n",
    "regexp = re.compile(r'[ .,;\\'\\\"]víctimas[ .,;\\'\\\"]')\n",
    "data_paz = ''\n",
    "for s in sentences: \n",
    "    if regexp.search(s.lower()): \n",
    "        data_paz = data_paz + '\\n' + s\n",
    "\n",
    "stop_words = stop_words_spanish\n",
    "stop_words.append('víctimas')\n",
    "final6 = getNGram(data_paz, 2,stop_words , 20)\n",
    "print(tabulate(final6, ['Ngram', 'Number']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
